"""
Scraper do Promobit para o sistema Garimpeiro Geek.
Coleta ofertas em tempo real da comunidade Promobit.
"""

import asyncio
import logging
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import re
import json

from ...core.models import Offer
from ...core.affiliate_validator import AffiliateValidator
from ...utils.anti_bot import get_random_user_agent


@dataclass
class PromobitOffer:
    """Oferta do Promobit."""
    title: str
    price: float
    original_price: Optional[float]
    discount: Optional[int]
    store: str
    category: str
    url: str
    image_url: Optional[str]
    posted_at: datetime
    votes: int
    comments: int
    hot: bool


class PromobitScraper:
    """Scraper para o site Promobit."""
    
    def __init__(self):
        """Inicializa o scraper."""
        self.logger = logging.getLogger(__name__)
        self.base_url = "https://www.promobit.com.br"
        self.validator = AffiliateValidator()
        
        # Configura√ß√µes
        self.max_offers_per_page = 50
        self.rate_limit_delay = 1.0  # segundos entre requisi√ß√µes
        self.max_retries = 3
        
        # Cache de ofertas j√° processadas
        self.processed_offers = set()
        
        # Estat√≠sticas
        self.stats = {
            "total_scraped": 0,
            "valid_offers": 0,
            "invalid_offers": 0,
            "last_scrape": None,
            "errors": 0
        }
    
    async def scrape_offers(self, max_offers: int = 100) -> List[Offer]:
        """
        Coleta ofertas do Promobit.
        
        Args:
            max_offers: M√°ximo de ofertas a coletar
            
        Returns:
            Lista de ofertas v√°lidas
        """
        try:
            self.logger.info(f"üï∑Ô∏è Iniciando coleta de ofertas do Promobit (m√°x: {max_offers})")
            
            offers = []
            page = 1
            
            while len(offers) < max_offers:
                self.logger.info(f"  üìÑ Coletando p√°gina {page}")
                
                # Coletar ofertas da p√°gina
                page_offers = await self._scrape_page(page)
                
                if not page_offers:
                    self.logger.info("  ‚ö†Ô∏è Nenhuma oferta encontrada na p√°gina, parando")
                    break
                
                # Processar ofertas da p√°gina
                for promobit_offer in page_offers:
                    if len(offers) >= max_offers:
                        break
                    
                    # Converter para modelo Offer
                    offer = await self._convert_to_offer(promobit_offer)
                    
                    if offer and await self._validate_offer(offer):
                        offers.append(offer)
                        self.stats["valid_offers"] += 1
                    else:
                        self.stats["invalid_offers"] += 1
                    
                    # Rate limiting
                    await asyncio.sleep(self.rate_limit_delay)
                
                page += 1
                
                # Verificar se h√° mais p√°ginas
                if len(page_offers) < self.max_offers_per_page:
                    break
            
            # Atualizar estat√≠sticas
            self.stats["total_scraped"] += len(offers)
            self.stats["last_scrape"] = datetime.now()
            
            self.logger.info(f"‚úÖ Coleta conclu√≠da: {len(offers)} ofertas v√°lidas")
            return offers
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na coleta de ofertas: {e}")
            self.stats["errors"] += 1
            return []
    
    async def _scrape_page(self, page: int) -> List[PromobitOffer]:
        """
        Coleta ofertas de uma p√°gina espec√≠fica.
        
        Args:
            page: N√∫mero da p√°gina
            
        Returns:
            Lista de ofertas da p√°gina
        """
        try:
            # URL da p√°gina
            url = f"{self.base_url}/ofertas?page={page}"
            
            # Em produ√ß√£o, aqui seria feita a requisi√ß√£o HTTP real
            # Por enquanto, simulamos a coleta
            
            # Simular delay de requisi√ß√£o
            await asyncio.sleep(0.5)
            
            # Simular ofertas encontradas
            offers = []
            for i in range(min(20, self.max_offers_per_page)):
                offer = PromobitOffer(
                    title=f"Produto Teste {page}-{i}",
                    price=99.99 + i,
                    original_price=199.99 + i,
                    discount=50,
                    store="Loja Teste",
                    category="Eletr√¥nicos",
                    url=f"https://exemplo.com/produto-{page}-{i}",
                    image_url=None,
                    posted_at=datetime.now(),
                    votes=10 + i,
                    comments=5 + i,
                    hot=i < 5
                )
                offers.append(offer)
            
            return offers
            
        except Exception as e:
            self.logger.error(f"Erro ao coletar p√°gina {page}: {e}")
            return []
    
    async def _convert_to_offer(self, promobit_offer: PromobitOffer) -> Optional[Offer]:
        """
        Converte oferta do Promobit para modelo Offer.
        
        Args:
            promobit_offer: Oferta do Promobit
            
        Returns:
            Oferta convertida ou None se inv√°lida
        """
        try:
            # Validar dados b√°sicos
            if not promobit_offer.title or not promobit_offer.url:
                return None
            
            # Calcular desconto
            discount_percentage = None
            if promobit_offer.original_price and promobit_offer.price < promobit_offer.original_price:
                discount_percentage = int(
                    ((promobit_offer.original_price - promobit_offer.price) / promobit_offer.original_price) * 100
                )
            
            # Criar oferta
            offer = Offer(
                title=promobit_offer.title,
                current_price=promobit_offer.price,
                original_price=promobit_offer.original_price,
                discount_percentage=discount_percentage,
                affiliate_url=promobit_offer.url,
                platform="promobit",
                category=promobit_offer.category,
                store=promobit_offer.store,
                image_url=promobit_offer.image_url,
                posted_at=promobit_offer.posted_at
            )
            
            return offer
            
        except Exception as e:
            self.logger.error(f"Erro ao converter oferta: {e}")
            return None
    
    async def _validate_offer(self, offer: Offer) -> bool:
        """
        Valida se uma oferta pode ser processada.
        
        Args:
            offer: Oferta a ser validada
            
        Returns:
            True se v√°lida
        """
        try:
            # Verificar se j√° foi processada
            offer_hash = f"{offer.title}_{offer.affiliate_url}"
            if offer_hash in self.processed_offers:
                return False
            
            # Validar URL de afiliado
            validation = await self.validator.validate_url(offer.affiliate_url)
            if not validation.is_valid:
                return False
            
            # Validar pre√ßo
            if offer.current_price <= 0:
                return False
            
            # Adicionar ao cache de processadas
            self.processed_offers.add(offer_hash)
            
            return True
            
        except Exception as e:
            self.logger.error(f"Erro na valida√ß√£o da oferta: {e}")
            return False
    
    async def scrape_hot_offers(self, max_offers: int = 20) -> List[Offer]:
        """
        Coleta apenas ofertas em alta (hot).
        
        Args:
            max_offers: M√°ximo de ofertas a coletar
            
        Returns:
            Lista de ofertas em alta
        """
        self.logger.info(f"üî• Coletando ofertas em alta do Promobit (m√°x: {max_offers})")
        
        # Em produ√ß√£o, filtraria por ofertas hot
        # Por enquanto, retorna ofertas normais
        return await self.scrape_offers(max_offers)
    
    async def scrape_by_category(self, category: str, max_offers: int = 50) -> List[Offer]:
        """
        Coleta ofertas por categoria.
        
        Args:
            category: Categoria desejada
            max_offers: M√°ximo de ofertas a coletar
            
        Returns:
            Lista de ofertas da categoria
        """
        self.logger.info(f"üìÇ Coletando ofertas da categoria '{category}' (m√°x: {max_offers})")
        
        # Em produ√ß√£o, filtraria por categoria
        # Por enquanto, retorna ofertas normais
        return await self.scrape_offers(max_offers)
    
    def get_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas do scraper."""
        return self.stats.copy()
    
    def clear_cache(self):
        """Limpa cache de ofertas processadas."""
        self.processed_offers.clear()
        self.logger.info("üóëÔ∏è Cache de ofertas processadas limpo")
    
    async def health_check(self) -> bool:
        """Verifica sa√∫de do scraper."""
        try:
            # Testar coleta de uma p√°gina
            offers = await self._scrape_page(1)
            return len(offers) > 0
            
        except Exception as e:
            self.logger.error(f"Health check falhou: {e}")
            return False


# Inst√¢ncia global do scraper
promobit_scraper = PromobitScraper()
