#!/usr/bin/env python3
"""
Scraper corrigido para o Buscap√© - Comparador de pre√ßos
Coleta ofertas de produtos com pre√ßos e avalia√ß√µes
"""

import asyncio
import logging
import random
import re
from datetime import datetime
from typing import List, Dict, Any, Optional
from urllib.parse import urljoin

import aiohttp
from bs4 import BeautifulSoup

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("buscape_scraper_fixed.log", mode="a", encoding="utf-8"),
    ],
)
logger = logging.getLogger("buscape_scraper_fixed")

# User Agents para rota√ß√£o
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
]

# URLs base para busca de ofertas
BASE_URL = "https://www.buscape.com.br"

# Categorias de interesse para produtos geek/tech
CATEGORIAS = [
    "/notebook",
    "/tv",
    "/tablet",
    "/console-de-video-game",
    "/monitor",
    "/smartwatch",
    "/fone-de-ouvido-e-headset",
    "/caixa-de-som-bluetooth",
    "/impressora-e-multifuncional",
]


def get_random_headers() -> dict:
    """Retorna headers aleat√≥rios para evitar bloqueio."""
    return {
        "User-Agent": random.choice(USER_AGENTS),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "DNT": "1",
        "Upgrade-Insecure-Requests": "1",
        "Referer": "https://www.buscape.com.br/",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "same-origin",
        "Sec-Fetch-User": "?1",
        "Cache-Control": "max-age=0",
    }


def extrair_preco(texto: str) -> tuple[Optional[str], Optional[str]]:
    """
    Extrai pre√ßo atual e original de um texto.

    Args:
        texto: Texto contendo os pre√ßos

    Returns:
        tuple: (preco_atual, preco_original)
    """
    if not texto:
        return None, None

    # Encontra todos os valores num√©ricos no formato R$ X.XXX,XX
    precos = re.findall(r"R\$\s*([\d\.]+,\d{2})", texto)

    if not precos:
        return None, None

    # Remove o s√≠mbolo R$ e espa√ßos para padroniza√ß√£o
    precos = [p.strip() for p in precos]

    # Se tiver apenas um pre√ßo, retorna ele como pre√ßo atual
    if len(precos) == 1:
        return precos[0], None

    # Se tiver mais de um, assume que o primeiro √© o pre√ßo original e o segundo o com desconto
    return precos[1], precos[0]


def extrair_avaliacao(texto: str) -> Optional[float]:
    """
    Extrai avalia√ß√£o de um texto.

    Args:
        texto: Texto contendo a avalia√ß√£o

    Returns:
        float: Avalia√ß√£o encontrada ou None
    """
    if not texto:
        return None

    # Procura por padr√µes de avalia√ß√£o (ex: 4.5, 4,5, 4/5)
    match = re.search(r"(\d+[.,]\d+|\d+)(?:\s*/\s*5)?", texto)
    if match:
        try:
            valor = match.group(1).replace(",", ".")
            return float(valor)
        except ValueError:
            pass

    return None


async def buscar_ofertas_buscape(
    session: aiohttp.ClientSession, max_paginas: int = 3, delay: float = 1.0
) -> List[Dict[str, Any]]:
    """
    Busca ofertas no Buscap√© usando categorias espec√≠ficas.

    Args:
        session: Sess√£o HTTP ass√≠ncrona
        max_paginas: N√∫mero m√°ximo de p√°ginas para buscar
        delay: Delay entre requisi√ß√µes em segundos

    Returns:
        Lista de ofertas encontradas
    """
    ofertas = []

    try:
        # Busca em categorias espec√≠ficas
        for categoria in CATEGORIAS[:max_paginas]:
            try:
                url_categoria = urljoin(BASE_URL, categoria)
                logger.info(f"üîç Buscando ofertas em: {url_categoria}")

                headers = get_random_headers()

                async with session.get(
                    url_categoria, headers=headers, timeout=15
                ) as response:
                    if response.status != 200:
                        logger.warning(
                            f"‚ö†Ô∏è Erro ao acessar {url_categoria}: {response.status}"
                        )
                        continue

                    html = await response.text()
                    soup = BeautifulSoup(html, "html.parser")

                    # Salva HTML para debug se necess√°rio
                    if len(ofertas) == 0:  # Apenas na primeira categoria
                        with open("buscape_debug.html", "w", encoding="utf-8") as f:
                            f.write(html)
                        logger.info("‚úÖ HTML salvo em buscape_debug.html para debug")

                    # Busca por produtos usando seletores mais espec√≠ficos
                    produtos = []

                    # Busca por produtos usando seletores espec√≠ficos do Buscap√©
                    produtos = soup.select(".Hits_ProductCard__Bonl_")

                    if not produtos:
                        # Fallback: busca por elementos com links de produto
                        produtos = soup.find_all(
                            "a", href=re.compile(r"/notebook/|/celular/|/tv/")
                        )
                        logger.info(
                            f"üîÑ Fallback: {len(produtos)} produtos encontrados por links"
                        )

                    logger.info(
                        f"üîç Encontrados {len(produtos)} produtos para an√°lise em {categoria}"
                    )

                    for produto in produtos[:15]:  # Limita a 15 produtos por categoria
                        try:
                            oferta = extrair_oferta_produto(produto, categoria)
                            if oferta:
                                # Verifica se a oferta j√° foi adicionada
                                if not any(
                                    o["url_produto"] == oferta["url_produto"]
                                    for o in ofertas
                                ):
                                    ofertas.append(oferta)
                                    logger.debug(
                                        f"Oferta adicionada: {oferta['titulo']} - {oferta['preco']}"
                                    )

                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Erro ao extrair produto: {e}")
                            continue

                        # Delay entre produtos
                        await asyncio.sleep(delay * 0.1)

                    # Delay entre categorias
                    await asyncio.sleep(delay)

            except Exception as e:
                logger.error(f"‚ùå Erro ao processar categoria {categoria}: {e}")
                continue

        logger.info(f"‚úÖ {len(ofertas)} ofertas extra√≠das com sucesso")

    except Exception as e:
        logger.error(f"‚ùå Erro geral na busca: {e}")

    return ofertas


def extrair_oferta_produto(
    produto_element, categoria: str = None
) -> Optional[Dict[str, Any]]:
    """Extrai informa√ß√µes de uma oferta de produto do Buscap√©."""
    try:
        # T√≠tulo do produto
        titulo_elem = produto_element.select_one('[data-testid="product-card::name"]')

        if not titulo_elem:
            return None

        titulo = titulo_elem.get_text(strip=True)
        if not titulo or len(titulo) < 5:
            return None

        # URL do produto
        url_produto = ""
        link_elem = produto_element.find("a", href=True)
        if link_elem:
            href = link_elem.get("href", "")
            if href.startswith("/"):
                url_produto = urljoin(BASE_URL, href)
            elif href.startswith("http"):
                url_produto = href

        # Pre√ßo
        preco_elem = produto_element.select_one('[data-testid="product-card::price"]')

        preco_texto = ""
        if preco_elem:
            preco_texto = preco_elem.get_text(strip=True)

        preco_atual, preco_original = extrair_preco(preco_texto)

        # Se n√£o conseguiu extrair pre√ßo, tenta do texto geral
        if not preco_atual:
            texto_geral = produto_element.get_text()
            preco_atual, preco_original = extrair_preco(texto_geral)

        # Avalia√ß√£o
        avaliacao_elem = produto_element.select_one(
            '[data-testid="product-card::rating"]'
        )

        avaliacao_texto = ""
        if avaliacao_elem:
            avaliacao_texto = avaliacao_elem.get_text(strip=True)

        avaliacao = extrair_avaliacao(avaliacao_texto)

        # Loja
        loja_elem = produto_element.select_one(
            '[data-testid="product-card::best-merchant"]'
        )

        loja = "Buscap√©"
        if loja_elem:
            loja_texto = loja_elem.get_text(strip=True)
            if loja_texto and len(loja_texto) > 1:
                loja = loja_texto

        # Imagem
        img_elem = produto_element.select_one('[data-testid="product-card::image"] img')
        imagem_url = ""
        if img_elem:
            src = img_elem.get("src", "")
            if src.startswith("//"):
                imagem_url = f"https:{src}"
            elif src.startswith("/"):
                imagem_url = urljoin(BASE_URL, src)
            else:
                imagem_url = src

        # Cria a oferta
        oferta = {
            "titulo": titulo,
            "url_produto": url_produto or f"{BASE_URL}{categoria}",
            "url_fonte": f"{BASE_URL}{categoria}",
            "preco": preco_atual or "Pre√ßo n√£o informado",
            "preco_original": preco_original,
            "loja": loja,
            "fonte": "Buscap√©",
            "imagem_url": imagem_url,
            "avaliacao": avaliacao,
            "categoria": categoria.replace("/", "") if categoria else "Geral",
            "data_coleta": datetime.now().isoformat(),
        }

        return oferta

    except Exception as e:
        logger.error(f"Erro ao extrair oferta: {e}")
        return None


async def main():
    """Fun√ß√£o de teste para o m√≥dulo."""
    async with aiohttp.ClientSession() as session:
        ofertas = await buscar_ofertas_buscape(session, max_paginas=2)

        print(f"\n=== OFERTAS ENCONTRADAS ({len(ofertas)}) ===\n")

        for i, oferta in enumerate(
            ofertas[:5], 1
        ):  # Mostra apenas as 5 primeiras para teste
            print(f"\n--- Oferta {i} ---")
            print(f"T√≠tulo: {oferta['titulo']}")
            print(f"Loja: {oferta['loja']}")
            print(f"Pre√ßo: {oferta['preco']}")
            if oferta["preco_original"]:
                print(f"Pre√ßo original: {oferta['preco_original']}")
            if oferta["avaliacao"]:
                print(f"Avalia√ß√£o: {oferta['avaliacao']}/5")
            print(f"Categoria: {oferta['categoria']}")
            print(f"URL: {oferta['url_produto']}")
            print(f"Fonte: {oferta['fonte']}")
            if oferta["imagem_url"]:
                print(f"Imagem: {oferta['imagem_url']}")
            print("-" * 50)


if __name__ == "__main__":
    # Configura logging para debug
    logger.setLevel(logging.DEBUG)
    handler = logging.StreamHandler()
    handler.setFormatter(
        logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    )
    logger.addHandler(handler)

    # Executa o teste
    asyncio.run(main())
