#!/usr/bin/env python3
"""
Scraper da Shopee usando Playwright - Vers√£o 3.0 com Tratamento de Bloqueios
Lida com autentica√ß√£o, captchas e bloqueios anti-bot
"""

import asyncio
import logging
import time
from base_playwright_scraper import BasePlaywrightScraper
import re

# Configura√ß√£o de logging
logger = logging.getLogger(__name__)


class ShopeePlaywrightScraperV3(BasePlaywrightScraper):
    """Scraper da Shopee usando Playwright - Vers√£o 3.0 com Tratamento de Bloqueios"""

    def __init__(self, headless: bool = False):  # Modo vis√≠vel para debug
        super().__init__(
            base_url="https://shopee.com.br",
            store_name="Shopee Brasil",
            headless=headless,
        )

        # Categorias populares para buscar ofertas
        self.categorias = [
            "smartphone",
            "notebook",
            "fone de ouvido",
            "smart tv",
            "console de videogame",
            "c√¢mera digital",
            "tablet",
            "smartwatch",
        ]

        # Seletores atualizados da Shopee (baseados em an√°lise real)
        self.product_selectors = [
            '[data-sqe="link"]',  # Container principal do produto
            ".shopee-search-item-result__item",  # Item de resultado
            '[class*="shopee-search-item-result"]',  # Classe gen√©rica
            '[class*="item"]',  # Fallback gen√©rico
            '[class*="product"]',  # Fallback gen√©rico
            '[class*="card"]',  # Fallback gen√©rico
        ]

        self.title_selectors = [
            '[data-sqe="name"]',  # Nome do produto
            ".ie3A\\+n",  # Classe espec√≠fica da Shopee
            '[class*="title"]',  # T√≠tulo gen√©rico
            '[class*="name"]',  # Nome gen√©rico
            "h1",
            "h2",
            "h3",
            "h4",  # Headers como fallback
        ]

        self.price_selectors = [
            ".ie3A\\+n\\+b",  # Classe espec√≠fica de pre√ßo da Shopee
            '[class*="price"]',  # Pre√ßo gen√©rico
            ".price",  # Classe de pre√ßo
            '[class*="cost"]',  # Custo gen√©rico
            '[class*="value"]',  # Valor gen√©rico
        ]

        self.link_selectors = [
            'a[href*="/product/"]',  # Links de produto
            'a[href*="/item/"]',  # Links de item
            '[data-sqe="link"] a',  # Link dentro do container
            'a[href*="/"]',  # Qualquer link como fallback
        ]

        self.image_selectors = [
            'img[src*="shopee"]',  # Imagens da Shopee
            "img[data-src]",  # Imagens com data-src
            "img",  # Qualquer imagem como fallback
        ]

        self.discount_selectors = [
            '[class*="discount"]',  # Desconto gen√©rico
            '[class*="off"]',  # Off gen√©rico
            ".badge",  # Badge gen√©rico
            '[class*="badge"]',  # Badge gen√©rico
        ]

    async def check_page_status(self, page_content: str) -> str:
        """Verifica o status da p√°gina e identifica bloqueios"""
        try:
            # Verifica se √© p√°gina de login
            if "Entre" in page_content and "login" in page_content.lower():
                return "LOGIN_REQUIRED"

            # Verifica se √© captcha
            if (
                "captcha" in page_content.lower()
                or "verifica√ß√£o" in page_content.lower()
            ):
                return "CAPTCHA_REQUIRED"

            # Verifica se √© bloqueio
            if "bloqueado" in page_content.lower() or "blocked" in page_content.lower():
                return "BLOCKED"

            # Verifica se √© p√°gina de resultados
            if "resultado" in page_content.lower() or "search" in page_content.lower():
                return "SEARCH_RESULTS"

            # Verifica se √© p√°gina inicial
            if "shopee" in page_content.lower() and len(page_content) > 10000:
                return "HOME_PAGE"

            return "UNKNOWN"

        except Exception as e:
            logger.error(f"‚ùå Erro ao verificar status da p√°gina: {e}")
            return "ERROR"

    async def handle_login_page(self):
        """Tenta contornar a p√°gina de login"""
        try:
            logger.info("üîê Detectada p√°gina de login, tentando contornar...")

            # Tenta acessar diretamente a p√°gina inicial
            await self.page.goto(f"{self.base_url}", wait_until="networkidle")
            await asyncio.sleep(3)

            # Verifica se ainda est√° na p√°gina de login
            page_content = await self.page.content()
            if "Entre" in page_content:
                logger.warning(
                    "‚ö†Ô∏è Ainda na p√°gina de login, tentando outras estrat√©gias..."
                )

                # Tenta acessar uma categoria espec√≠fica
                await self.page.goto(
                    f"{self.base_url}/category/11013230", wait_until="networkidle"
                )
                await asyncio.sleep(3)

                # Verifica novamente
                page_content = await self.page.content()
                if "Entre" in page_content:
                    logger.error("‚ùå N√£o foi poss√≠vel contornar a p√°gina de login")
                    return False
                else:
                    logger.info("‚úÖ Conseguiu contornar a p√°gina de login")
                    return True
            else:
                logger.info("‚úÖ Conseguiu contornar a p√°gina de login")
                return True

        except Exception as e:
            logger.error(f"‚ùå Erro ao tentar contornar login: {e}")
            return False

    async def handle_captcha(self):
        """Tenta resolver captcha ou aguarda resolu√ß√£o manual"""
        try:
            logger.info("ü§ñ Detectado captcha, aguardando resolu√ß√£o manual...")

            # Aguarda at√© 60 segundos para resolu√ß√£o manual
            for i in range(60):
                await asyncio.sleep(1)

                # Verifica se o captcha foi resolvido
                page_content = await self.page.content()
                if "captcha" not in page_content.lower():
                    logger.info("‚úÖ Captcha parece ter sido resolvido")
                    return True

                if i % 10 == 0:  # Log a cada 10 segundos
                    logger.info(f"‚è≥ Aguardando resolu√ß√£o do captcha... ({i}s)")

            logger.warning("‚ö†Ô∏è Timeout aguardando captcha")
            return False

        except Exception as e:
            logger.error(f"‚ùå Erro ao lidar com captcha: {e}")
            return False

    async def search_products_alternative(self, categoria: str) -> list:
        """M√©todo alternativo de busca que n√£o depende de login"""
        try:
            logger.info(f"üîç Tentando busca alternativa para: {categoria}")

            # Tenta acessar categoria direta
            category_url = (
                f"{self.base_url}/category/11013230"  # Categoria de smartphones
            )
            await self.page.goto(category_url, wait_until="networkidle")
            await asyncio.sleep(3)

            # Verifica se conseguiu acessar
            page_content = await self.page.content()
            status = await self.check_page_status(page_content)

            if status == "LOGIN_REQUIRED":
                logger.warning("‚ö†Ô∏è Categoria tamb√©m requer login")
                return []

            # Faz scroll para carregar produtos
            await self.scroll_page_smart(2.0)
            await asyncio.sleep(3)

            # Procura por produtos usando seletores gen√©ricos
            products = []

            # Procura por links que parecem ser de produtos
            product_links = await self.page.query_selector_all(
                'a[href*="/product/"], a[href*="/item/"]'
            )

            if product_links:
                logger.info(f"‚úÖ Encontrados {len(product_links)} links de produto")

                for i, link in enumerate(product_links[:10]):  # Limita a 10 produtos
                    try:
                        # Extrai informa√ß√µes b√°sicas
                        href = await link.get_attribute("href")
                        text = await link.text_content()

                        if href and text:
                            # Cria produto b√°sico
                            product = {
                                "titulo": text.strip()[:100],
                                "preco": "Pre√ßo n√£o dispon√≠vel",
                                "link": f"{self.base_url}{href}"
                                if not href.startswith("http")
                                else href,
                                "imagem": None,
                                "desconto": None,
                                "loja": "Shopee Brasil",
                                "categoria": categoria,
                                "timestamp": time.time(),
                            }

                            # Tenta extrair pre√ßo do texto
                            if "R$" in text:
                                price_match = re.search(r"R\$\s*(\d+[,\d]*)", text)
                                if price_match:
                                    product["preco"] = price_match.group(1)

                            products.append(product)

                    except Exception as e:
                        logger.debug(f"‚ö†Ô∏è Erro ao extrair produto {i}: {e}")
                        continue

            return products

        except Exception as e:
            logger.error(f"‚ùå Erro na busca alternativa: {e}")
            return []

    async def debug_page_structure(self, categoria: str):
        """Debug: analisa a estrutura da p√°gina para encontrar seletores corretos"""
        try:
            logger.info(f"üîç DEBUG: Analisando estrutura da p√°gina para {categoria}")

            # Constr√≥i URL de busca
            search_url = (
                f"{self.base_url}/search?keyword={categoria}&sortBy=sales&order=desc"
            )

            # Acessa a p√°gina
            await self.page.goto(search_url, wait_until="networkidle")
            await asyncio.sleep(5)  # Aguarda carregamento completo

            # Verifica o status da p√°gina
            page_content = await self.page.content()
            status = await self.check_page_status(page_content)
            logger.info(f"üìä Status da p√°gina: {status}")

            if status == "LOGIN_REQUIRED":
                logger.warning("‚ö†Ô∏è P√°gina requer login, tentando contornar...")
                if not await self.handle_login_page():
                    logger.error("‚ùå N√£o foi poss√≠vel contornar o login")
                    return

                # Tenta acessar novamente
                await self.page.goto(search_url, wait_until="networkidle")
                await asyncio.sleep(5)
                page_content = await self.page.content()
                status = await self.check_page_status(page_content)
                logger.info(f"üìä Novo status da p√°gina: {status}")

            if status == "CAPTCHA_REQUIRED":
                logger.warning("‚ö†Ô∏è Captcha detectado, tentando resolver...")
                if not await self.handle_captcha():
                    logger.error("‚ùå N√£o foi poss√≠vel resolver o captcha")
                    return

            # Faz scroll para carregar conte√∫do din√¢mico
            await self.scroll_page_smart(2.0)
            await asyncio.sleep(3)

            # Analisa elementos da p√°gina
            logger.info("üîç DEBUG: Analisando elementos da p√°gina...")

            # Procura por containers de produto
            for i, selector in enumerate(self.product_selectors):
                try:
                    elements = await self.page.query_selector_all(selector)
                    if elements:
                        logger.info(
                            f"‚úÖ Selector {i + 1} ({selector}): {len(elements)} elementos encontrados"
                        )

                        # Analisa o primeiro elemento
                        if len(elements) > 0:
                            first_element = elements[0]

                            # Tenta extrair informa√ß√µes b√°sicas
                            try:
                                # T√≠tulo
                                title_text = await first_element.text_content()
                                if title_text:
                                    logger.info(
                                        f"   üìù Texto do elemento: {title_text[:100]}..."
                                    )

                                # HTML interno
                                inner_html = await first_element.inner_html()
                                if inner_html:
                                    logger.info(
                                        f"   üèóÔ∏è HTML interno: {inner_html[:200]}..."
                                    )

                                # Classes
                                classes = await first_element.get_attribute("class")
                                if classes:
                                    logger.info(f"   üè∑Ô∏è Classes: {classes}")

                            except Exception as e:
                                logger.warning(f"   ‚ö†Ô∏è Erro ao analisar elemento: {e}")

                        break
                    else:
                        logger.info(f"‚ùå Selector {i + 1} ({selector}): 0 elementos")

                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro com selector {i + 1} ({selector}): {e}")

            # Procura por links de produto
            try:
                product_links = await self.page.query_selector_all(
                    'a[href*="/product/"], a[href*="/item/"]'
                )
                logger.info(f"üîó Links de produto encontrados: {len(product_links)}")

                if product_links:
                    for i, link in enumerate(
                        product_links[:3]
                    ):  # Analisa os primeiros 3
                        try:
                            href = await link.get_attribute("href")
                            text = await link.text_content()
                            logger.info(
                                f"   Link {i + 1}: {href} | Texto: {text[:50]}..."
                            )
                        except Exception as e:
                            logger.warning(f"   ‚ö†Ô∏è Erro ao analisar link {i + 1}: {e}")

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao procurar links: {e}")

            # Salva screenshot para an√°lise visual
            screenshot_path = f"shopee_debug_v3_{categoria}_{int(time.time())}.png"
            await self.page.screenshot(path=screenshot_path, full_page=True)
            logger.info(f"üì∏ Screenshot salvo: {screenshot_path}")

            # Salva HTML da p√°gina para an√°lise
            html_content = await self.page.content()
            html_path = f"shopee_debug_v3_{categoria}_{int(time.time())}.html"
            with open(html_path, "w", encoding="utf-8") as f:
                f.write(html_content)
            logger.info(f"üìÑ HTML salvo: {html_path}")

        except Exception as e:
            logger.error(f"‚ùå Erro no debug: {e}")

    async def buscar_ofertas_gerais(self):
        """Busca ofertas gerais de todas as categorias com tratamento de bloqueios"""
        todas_ofertas = []

        if not await self.setup_browser():
            logger.error("‚ùå N√£o foi poss√≠vel configurar o navegador")
            return []

        try:
            logger.info("üöÄ INICIANDO BUSCA DE OFERTAS NA SHOPEE COM PLAYWRIGHT V3.0")
            logger.info("=" * 60)

            # Testa apenas uma categoria para debug
            categoria_teste = "smartphone"
            logger.info(f"üîç TESTE: Analisando apenas {categoria_teste} para debug")

            # Executa debug da estrutura da p√°gina
            await self.debug_page_structure(categoria_teste)

            # Aguarda input do usu√°rio para continuar
            logger.info("‚è∏Ô∏è Pressione Enter para continuar com o scraping normal...")
            input()

            # Continua com o scraping normal
            for categoria in self.categorias:
                try:
                    logger.info(f"\nüîç Buscando: {categoria.upper()}")

                    # Constr√≥i URL de busca
                    search_url = f"{self.base_url}/search?keyword={categoria}&sortBy=sales&order=desc"

                    # Busca produtos usando m√©todo gen√©rico
                    ofertas_categoria = await self.search_products_by_category(
                        categoria=categoria,
                        search_url=search_url,
                        product_selectors=self.product_selectors,
                        title_selectors=self.title_selectors,
                        price_selectors=self.price_selectors,
                        link_selectors=self.link_selectors,
                        image_selectors=self.image_selectors,
                        discount_selectors=self.discount_selectors,
                    )

                    # Se n√£o encontrou produtos, tenta m√©todo alternativo
                    if not ofertas_categoria:
                        logger.info(f"üîÑ Tentando m√©todo alternativo para {categoria}")
                        ofertas_categoria = await self.search_products_alternative(
                            categoria
                        )

                    todas_ofertas.extend(ofertas_categoria)

                    # Delay entre categorias
                    await asyncio.sleep(self.get_random_delay(2, 4))

                except Exception as e:
                    logger.error(f"‚ùå Erro na categoria {categoria}: {e}")
                    continue

            # Remove duplicatas baseado no t√≠tulo
            ofertas_unicas = []
            titulos_vistos = set()

            for oferta in todas_ofertas:
                if oferta["titulo"] not in titulos_vistos:
                    ofertas_unicas.append(oferta)
                    titulos_vistos.add(oferta["titulo"])

            logger.info(f"\nüéØ TOTAL DE OFERTAS √öNICAS: {len(ofertas_unicas)}")

        except Exception as e:
            logger.error(f"‚ùå Erro geral na busca: {e}")

        finally:
            await self.close_browser()

        return todas_ofertas


async def main():
    """Fun√ß√£o principal para teste"""
    print("üöÄ TESTANDO SHOPEE SCRAPER COM PLAYWRIGHT V3.0 (TRATAMENTO DE BLOQUEIOS)")
    print("=" * 60)

    scraper = ShopeePlaywrightScraperV3(headless=False)  # Modo vis√≠vel para debug

    # Testa conex√£o primeiro
    if not await scraper.test_connection():
        print("‚ùå N√£o foi poss√≠vel conectar com a Shopee")
        return

    # Busca ofertas
    ofertas = await scraper.buscar_ofertas_gerais()

    print(f"\nüéØ RESULTADO: {len(ofertas)} ofertas encontradas")
    print("=" * 60)

    for i, oferta in enumerate(ofertas[:10], 1):  # Mostra apenas as primeiras 10
        print(f"\n{i}. {oferta['titulo']}")
        print(f"   üí∞ Pre√ßo: {oferta['preco']}")
        if oferta.get("desconto"):
            print(f"   üè∑Ô∏è Desconto: {oferta['desconto']}%")
        print(f"   üè™ Loja: {oferta['loja']}")
        print(f"   üìÇ Categoria: {oferta['categoria']}")
        if oferta.get("link"):
            print(f"   üîó Link: {oferta['link'][:80]}...")

    # Salva as ofertas em arquivo JSON
    if ofertas:
        filename = scraper.save_results(ofertas, "ofertas_shopee_playwright_v3")
        if filename:
            print(f"\nüíæ Ofertas salvas em: {filename}")


if __name__ == "__main__":
    asyncio.run(main())
